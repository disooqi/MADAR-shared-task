{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from preparedata import prepare_train_data_for_task_1, prepare_dev_data_for_task_1, prepare_test_data_for_task_1\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['مانقدرش ندير الأمتعة ديالي تحت الكرسي . تقدر تخليهم ، عافاك ؟',\n",
       " 'ما عندك مانع أجي لعندك ؟',\n",
       " 'هدول مش صناعة يابانية ، هما هيك ؟']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = 'corpus-26'\n",
    "\n",
    "_train_src, _, train_tgt, _ = prepare_train_data_for_task_1(corpus= corpus)\n",
    "_dev_src, dev_tgt = prepare_dev_data_for_task_1(corpus= corpus)\n",
    "_test_src = prepare_test_data_for_task_1(corpus= corpus)\n",
    "\n",
    "train_src = _train_src[:]\n",
    "dev_src = _dev_src[:]\n",
    "test_src = _test_src[:]\n",
    "train_src[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27364"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec =CountVectorizer(analyzer='word',  min_df=1, max_df=0.95, ngram_range=(1, 1))\n",
    "X_train_counts = count_vec.fit_transform(train_src)\n",
    "X_dev_counts = count_vec.transform(dev_src)\n",
    "\n",
    "tf_vec = TfidfTransformer(use_idf=False)\n",
    "X_train_tf = tf_vec.fit_transform(X_train_counts)\n",
    "X_dev_tf = tf_vec.transform(X_dev_counts)\n",
    "\n",
    "tfidf_vect = TfidfTransformer(use_idf=True, smooth_idf=False, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf_vect.fit_transform(X_train_counts)\n",
    "X_dev_tfidf = tfidf_vect.transform(X_dev_counts)\n",
    "\n",
    "len(count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Doc=====\n",
      "ذهب محمد الى المدرسة .\n",
      "\n",
      "===Keywords===\n",
      "محمد 0.623\n",
      "المدرسة 0.617\n"
     ]
    }
   ],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "\n",
    "feature_names = count_vec.get_feature_names()\n",
    "# get the document that we want to extract keywords from\n",
    "doc=\"ذهب محمد الى المدرسة .\"\n",
    " \n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_vect.transform(count_vec.transform([doc]))\n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,2)\n",
    " \n",
    "# now print the results\n",
    "print(\"\\n=====Doc=====\")\n",
    "print(doc)\n",
    "print(\"\\n===Keywords===\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41600, 27364), (5200, 27364))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = X_train_tfidf.toarray()\n",
    "dd = X_dev_tfidf.toarray()\n",
    "tt.shape, dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc:  81.51 %\n",
      "Testing Acc:  63.02 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALE       0.62      0.56      0.59       200\n",
      "         ALG       0.73      0.80      0.76       200\n",
      "         ALX       0.71      0.78      0.74       200\n",
      "         AMM       0.43      0.53      0.48       200\n",
      "         ASW       0.47      0.60      0.53       200\n",
      "         BAG       0.74      0.58      0.65       200\n",
      "         BAS       0.68      0.64      0.66       200\n",
      "         BEI       0.77      0.57      0.66       200\n",
      "         BEN       0.66      0.70      0.68       200\n",
      "         CAI       0.65      0.42      0.51       200\n",
      "         DAM       0.65      0.51      0.57       200\n",
      "         DOH       0.58      0.62      0.60       200\n",
      "         FES       0.64      0.70      0.67       200\n",
      "         JED       0.63      0.61      0.62       200\n",
      "         JER       0.45      0.59      0.51       200\n",
      "         KHA       0.49      0.69      0.57       200\n",
      "         MOS       0.82      0.79      0.80       200\n",
      "         MSA       0.60      0.82      0.69       200\n",
      "         MUS       0.59      0.41      0.48       200\n",
      "         RAB       0.74      0.56      0.64       200\n",
      "         RIY       0.51      0.61      0.56       200\n",
      "         SAL       0.53      0.48      0.50       200\n",
      "         SAN       0.81      0.69      0.75       200\n",
      "         SFX       0.70      0.77      0.73       200\n",
      "         TRI       0.73      0.73      0.73       200\n",
      "         TUN       0.80      0.64      0.71       200\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      5200\n",
      "   macro avg       0.64      0.63      0.63      5200\n",
      "weighted avg       0.64      0.63      0.63      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_1 = MultinomialNB().fit(X_train_tfidf, train_tgt)\n",
    "\n",
    "train_pred = clf_1.predict(X_train_tfidf)\n",
    "dev_pred_1 = clf_1.predict(X_dev_tfidf)\n",
    "\n",
    "print('Training Acc: ',np.around(np.mean(train_pred == train_tgt)*100,2), '%')\n",
    "print('Testing Acc: ',np.around(np.mean(dev_pred_1 == dev_tgt)*100,2), '%')\n",
    "\n",
    "print(metrics.classification_report(dev_tgt, dev_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc:  65.57 %\n",
      "Testing Acc:  55.92 %\n"
     ]
    }
   ],
   "source": [
    "tfidf_ch_vect = TfidfVectorizer(analyzer= 'char',lowercase=False, max_df=0.95,ngram_range=(2, 5), smooth_idf=False,\n",
    "                             sublinear_tf=True)\n",
    "\n",
    "X_train = tfidf_ch_vect.fit_transform(train_src)\n",
    "X_dev = tfidf_ch_vect.transform(dev_src)\n",
    "\n",
    "clf_2 = SGDClassifier('log', max_iter=1000, tol=1e-3, n_jobs=-1)\n",
    "clf_2.fit(X_train, train_tgt)\n",
    "train_pred = clf_2.predict(X_train)\n",
    "dev_pred_2 = clf_2.predict(X_dev)\n",
    "\n",
    "print('Training Acc: ',np.around(np.mean(train_pred == train_tgt)*100,2), '%')\n",
    "print('Testing Acc: ',np.around(np.mean(dev_pred_2 == dev_tgt)*100,2), '%')\n",
    "t = metrics.classification_report(dev_tgt, dev_pred_2)\n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc:  78.01 %\n",
      "Testing Acc:  61.42 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ALE       0.61      0.57      0.59       200\n",
      "         ALG       0.71      0.78      0.74       200\n",
      "         ALX       0.71      0.77      0.74       200\n",
      "         AMM       0.47      0.49      0.48       200\n",
      "         ASW       0.49      0.59      0.54       200\n",
      "         BAG       0.69      0.54      0.60       200\n",
      "         BAS       0.66      0.65      0.65       200\n",
      "         BEI       0.67      0.60      0.63       200\n",
      "         BEN       0.62      0.65      0.63       200\n",
      "         CAI       0.68      0.44      0.53       200\n",
      "         DAM       0.56      0.47      0.51       200\n",
      "         DOH       0.57      0.60      0.58       200\n",
      "         FES       0.65      0.66      0.65       200\n",
      "         JED       0.55      0.59      0.57       200\n",
      "         JER       0.47      0.59      0.52       200\n",
      "         KHA       0.49      0.68      0.57       200\n",
      "         MOS       0.80      0.78      0.79       200\n",
      "         MSA       0.59      0.82      0.69       200\n",
      "         MUS       0.60      0.38      0.46       200\n",
      "         RAB       0.67      0.55      0.60       200\n",
      "         RIY       0.53      0.57      0.55       200\n",
      "         SAL       0.56      0.46      0.50       200\n",
      "         SAN       0.75      0.69      0.72       200\n",
      "         SFX       0.62      0.75      0.68       200\n",
      "         TRI       0.75      0.70      0.73       200\n",
      "         TUN       0.67      0.60      0.64       200\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      5200\n",
      "   macro avg       0.62      0.61      0.61      5200\n",
      "weighted avg       0.62      0.61      0.61      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf_1), ('rf', clf_2)], voting='soft', flatten_transform=True)\n",
    "\n",
    "eclf1.fit(X_train_tfidf, train_tgt)\n",
    "train_pred = eclf1.predict(X_train_tfidf)\n",
    "dev_pred_3 = eclf1.predict(X_dev_tfidf)\n",
    "\n",
    "print('Training Acc: ',np.around(np.mean(train_pred == train_tgt)*100,2), '%')\n",
    "print('Testing Acc: ',np.around(np.mean(dev_pred_3 == dev_tgt)*100,2), '%')\n",
    "t = metrics.classification_report(dev_tgt, dev_pred_3)\n",
    "print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
